{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceDream\n",
    "\n",
    "Here, I try dreaming using an image classifier trained on a dataset of facial images.\n",
    "\n",
    "I heavily borrowed from [krasserm's face-recognition project](https://github.com/krasserm/face-recognition) to get the pretrained model loaded into Tensorflow 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from deepdream import dream\n",
    "\n",
    "from openface.model import create_model\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the path to the picture you'd like to dream upon below\n",
    "image_path = '../img/horse.jpg'\n",
    "\n",
    "\n",
    "# if you'd like to save your dreamed picture, replace 'None' with a file path below\n",
    "output_path = None\n",
    "\n",
    "\n",
    "# These are the names of the layers for which we try to maximize activation.\n",
    "layer_contributions = {\n",
    "    'activation_69': .5,\n",
    "    'activation_70': 2.,\n",
    "    'activation_72': 1.5,\n",
    "    'activation_71': 2.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_2': <tensorflow.python.keras.engine.input_layer.InputLayer at 0xb3c61b7f0>,\n",
       " 'zero_padding2d_23': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3c61b940>,\n",
       " 'conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c61bcf8>,\n",
       " 'bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb299daa90>,\n",
       " 'activation_37': <tensorflow.python.keras.layers.core.Activation at 0xb3c628f60>,\n",
       " 'zero_padding2d_24': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3c62f160>,\n",
       " 'max_pooling2d_6': <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0xb3c62f2b0>,\n",
       " 'lrn_1': <tensorflow.python.keras.layers.core.Lambda at 0xb3c666668>,\n",
       " 'conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c6668d0>,\n",
       " 'bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c666c88>,\n",
       " 'activation_38': <tensorflow.python.keras.layers.core.Activation at 0xb3c66f908>,\n",
       " 'zero_padding2d_25': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3c66f668>,\n",
       " 'conv3': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c66fda0>,\n",
       " 'bn3': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c68ce80>,\n",
       " 'activation_39': <tensorflow.python.keras.layers.core.Activation at 0xb3c6abef0>,\n",
       " 'lrn_2': <tensorflow.python.keras.layers.core.Lambda at 0xb3c6aba90>,\n",
       " 'zero_padding2d_26': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3c6abba8>,\n",
       " 'max_pooling2d_7': <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0xb3c6c5d68>,\n",
       " 'inception_3a_3x3_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c6de9e8>,\n",
       " 'inception_3a_5x5_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c7539e8>,\n",
       " 'inception_3a_3x3_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c6debe0>,\n",
       " 'inception_3a_5x5_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c802d68>,\n",
       " 'activation_40': <tensorflow.python.keras.layers.core.Activation at 0xb3c6e95f8>,\n",
       " 'activation_42': <tensorflow.python.keras.layers.core.Activation at 0xb3c81e4e0>,\n",
       " 'max_pooling2d_8': <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0xb3c634978>,\n",
       " 'zero_padding2d_27': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3c6e9780>,\n",
       " 'zero_padding2d_28': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3c81e7b8>,\n",
       " 'inception_3a_pool_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c89ee10>,\n",
       " 'inception_3a_3x3_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c6f3cc0>,\n",
       " 'inception_3a_5x5_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c827c50>,\n",
       " 'inception_3a_pool_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c950a20>,\n",
       " 'inception_3a_1x1_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c959240>,\n",
       " 'inception_3a_3x3_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c734da0>,\n",
       " 'inception_3a_5x5_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c868d30>,\n",
       " 'activation_44': <tensorflow.python.keras.layers.core.Activation at 0xb3c9509b0>,\n",
       " 'inception_3a_1x1_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c97fd30>,\n",
       " 'activation_41': <tensorflow.python.keras.layers.core.Activation at 0xb3c753860>,\n",
       " 'activation_43': <tensorflow.python.keras.layers.core.Activation at 0xb3c6347f0>,\n",
       " 'zero_padding2d_29': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3c950c88>,\n",
       " 'activation_45': <tensorflow.python.keras.layers.core.Activation at 0xb3c993550>,\n",
       " 'concatenate_7': <tensorflow.python.keras.layers.merge.Concatenate at 0xb3c993048>,\n",
       " 'inception_3b_3x3_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c993cc0>,\n",
       " 'inception_3b_5x5_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c9e52b0>,\n",
       " 'inception_3b_3x3_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c60d4a8>,\n",
       " 'inception_3b_5x5_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3ca0bf98>,\n",
       " 'activation_46': <tensorflow.python.keras.layers.core.Activation at 0xb3c9af710>,\n",
       " 'activation_48': <tensorflow.python.keras.layers.core.Activation at 0xb3ca1c6a0>,\n",
       " 'average_pooling2d_4': <tensorflow.python.keras.layers.pooling.AveragePooling2D at 0xb3ca82208>,\n",
       " 'zero_padding2d_30': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3c9af208>,\n",
       " 'zero_padding2d_31': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3ca1c080>,\n",
       " 'inception_3b_pool_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3ca952b0>,\n",
       " 'inception_3b_3x3_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3c9af1d0>,\n",
       " 'inception_3b_5x5_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3ca1c048>,\n",
       " 'inception_3b_pool_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3caa6860>,\n",
       " 'inception_3b_1x1_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3cbc6fd0>,\n",
       " 'inception_3b_3x3_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3c9d9940>,\n",
       " 'inception_3b_5x5_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3ca71898>,\n",
       " 'activation_50': <tensorflow.python.keras.layers.core.Activation at 0xb3cbb40f0>,\n",
       " 'inception_3b_1x1_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3cbd9d30>,\n",
       " 'activation_47': <tensorflow.python.keras.layers.core.Activation at 0xb3c9e5080>,\n",
       " 'activation_49': <tensorflow.python.keras.layers.core.Activation at 0xb3ca82400>,\n",
       " 'zero_padding2d_32': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3cbb44e0>,\n",
       " 'activation_51': <tensorflow.python.keras.layers.core.Activation at 0xb3cbef518>,\n",
       " 'concatenate_8': <tensorflow.python.keras.layers.merge.Concatenate at 0xb3cbefd68>,\n",
       " 'inception_3c_3x3_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3cbef5f8>,\n",
       " 'inception_3c_5x5_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3cc5fc50>,\n",
       " 'inception_3c_3x3_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3cc0ef28>,\n",
       " 'inception_3c_5x5_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3cfd8f60>,\n",
       " 'activation_52': <tensorflow.python.keras.layers.core.Activation at 0xb3cc28748>,\n",
       " 'activation_54': <tensorflow.python.keras.layers.core.Activation at 0xb3cff66d8>,\n",
       " 'zero_padding2d_33': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3cc28f28>,\n",
       " 'zero_padding2d_34': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3cff6f60>,\n",
       " 'inception_3c_3x3_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3cc30198>,\n",
       " 'inception_3c_5x5_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d0019b0>,\n",
       " 'inception_3c_3x3_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3cc3dfd0>,\n",
       " 'inception_3c_5x5_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d010fd0>,\n",
       " 'max_pooling2d_9': <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0xb3d031c50>,\n",
       " 'activation_53': <tensorflow.python.keras.layers.core.Activation at 0xb3cc5fa58>,\n",
       " 'activation_55': <tensorflow.python.keras.layers.core.Activation at 0xb3d031a58>,\n",
       " 'zero_padding2d_35': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3d07d438>,\n",
       " 'concatenate_9': <tensorflow.python.keras.layers.merge.Concatenate at 0xb3d07df28>,\n",
       " 'inception_4a_3x3_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d07def0>,\n",
       " 'inception_4a_5x5_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d196b38>,\n",
       " 'inception_4a_3x3_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d09ac88>,\n",
       " 'inception_4a_5x5_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d252ef0>,\n",
       " 'activation_56': <tensorflow.python.keras.layers.core.Activation at 0xb3d0a8668>,\n",
       " 'activation_58': <tensorflow.python.keras.layers.core.Activation at 0xb3d270668>,\n",
       " 'average_pooling2d_5': <tensorflow.python.keras.layers.pooling.AveragePooling2D at 0xb3d2a8b38>,\n",
       " 'zero_padding2d_36': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3d0a8940>,\n",
       " 'zero_padding2d_37': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3d270940>,\n",
       " 'inception_4a_pool_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d2c4f98>,\n",
       " 'inception_4a_3x3_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d0afdd8>,\n",
       " 'inception_4a_5x5_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d276dd8>,\n",
       " 'inception_4a_pool_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d2dfc50>,\n",
       " 'inception_4a_1x1_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d2e7160>,\n",
       " 'inception_4a_3x3_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d17bf28>,\n",
       " 'inception_4a_5x5_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d28df28>,\n",
       " 'activation_60': <tensorflow.python.keras.layers.core.Activation at 0xb3d2dfc18>,\n",
       " 'inception_4a_1x1_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d317d30>,\n",
       " 'activation_57': <tensorflow.python.keras.layers.core.Activation at 0xb3d1969b0>,\n",
       " 'activation_59': <tensorflow.python.keras.layers.core.Activation at 0xb3d2a89b0>,\n",
       " 'zero_padding2d_38': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3d2e71d0>,\n",
       " 'activation_61': <tensorflow.python.keras.layers.core.Activation at 0xb3d3206d8>,\n",
       " 'concatenate_10': <tensorflow.python.keras.layers.merge.Concatenate at 0xb3d320208>,\n",
       " 'inception_4e_3x3_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d320160>,\n",
       " 'inception_4e_5x5_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d4a4ba8>,\n",
       " 'inception_4e_3x3_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d349908>,\n",
       " 'inception_4e_5x5_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d4c79b0>,\n",
       " 'activation_62': <tensorflow.python.keras.layers.core.Activation at 0xb3d36a438>,\n",
       " 'activation_64': <tensorflow.python.keras.layers.core.Activation at 0xb3d4da438>,\n",
       " 'zero_padding2d_39': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3d36a400>,\n",
       " 'zero_padding2d_40': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3d4da400>,\n",
       " 'inception_4e_3x3_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d37ddd8>,\n",
       " 'inception_4e_5x5_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3d50fdd8>,\n",
       " 'inception_4e_3x3_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d390c88>,\n",
       " 'inception_4e_5x5_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3d524c88>,\n",
       " 'max_pooling2d_10': <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0xb3d5395f8>,\n",
       " 'activation_63': <tensorflow.python.keras.layers.core.Activation at 0xb3d4a47b8>,\n",
       " 'activation_65': <tensorflow.python.keras.layers.core.Activation at 0xb3d539470>,\n",
       " 'zero_padding2d_41': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3da1ca90>,\n",
       " 'concatenate_11': <tensorflow.python.keras.layers.merge.Concatenate at 0xb3da1cdd8>,\n",
       " 'inception_5a_3x3_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3da1c978>,\n",
       " 'inception_5a_3x3_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3da2e6a0>,\n",
       " 'activation_66': <tensorflow.python.keras.layers.core.Activation at 0xb3da3d080>,\n",
       " 'average_pooling2d_6': <tensorflow.python.keras.layers.pooling.AveragePooling2D at 0xb3da77550>,\n",
       " 'zero_padding2d_42': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3da3d358>,\n",
       " 'inception_5a_pool_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3daa86d8>,\n",
       " 'inception_5a_3x3_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3da50c88>,\n",
       " 'inception_5a_pool_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3dabbc18>,\n",
       " 'inception_5a_1x1_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3dad6cf8>,\n",
       " 'inception_5a_3x3_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3da62be0>,\n",
       " 'activation_68': <tensorflow.python.keras.layers.core.Activation at 0xb3dacd588>,\n",
       " 'inception_5a_1x1_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3ddf7e48>,\n",
       " 'activation_67': <tensorflow.python.keras.layers.core.Activation at 0xb3da773c8>,\n",
       " 'zero_padding2d_43': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3dacd860>,\n",
       " 'activation_69': <tensorflow.python.keras.layers.core.Activation at 0xb3de128d0>,\n",
       " 'concatenate_12': <tensorflow.python.keras.layers.merge.Concatenate at 0xb3de12a58>,\n",
       " 'inception_5b_3x3_conv1': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3de12780>,\n",
       " 'inception_5b_3x3_bn1': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3de67a90>,\n",
       " 'activation_70': <tensorflow.python.keras.layers.core.Activation at 0xb3de679b0>,\n",
       " 'max_pooling2d_11': <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0xb3df2d160>,\n",
       " 'zero_padding2d_44': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3de67cf8>,\n",
       " 'inception_5b_pool_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3df40748>,\n",
       " 'inception_5b_3x3_conv2': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3de70470>,\n",
       " 'inception_5b_pool_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3df5f630>,\n",
       " 'inception_5b_1x1_conv': <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb3df7fba8>,\n",
       " 'inception_5b_3x3_bn2': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3df21dd8>,\n",
       " 'activation_72': <tensorflow.python.keras.layers.core.Activation at 0xb3df68400>,\n",
       " 'inception_5b_1x1_bn': <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 at 0xb3df8eb00>,\n",
       " 'activation_71': <tensorflow.python.keras.layers.core.Activation at 0xb3df2d5c0>,\n",
       " 'zero_padding2d_45': <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0xb3df68278>,\n",
       " 'activation_73': <tensorflow.python.keras.layers.core.Activation at 0xb3e2752e8>,\n",
       " 'concatenate_13': <tensorflow.python.keras.layers.merge.Concatenate at 0xb3e275470>,\n",
       " 'average_pooling2d_7': <tensorflow.python.keras.layers.pooling.AveragePooling2D at 0xb3e275198>,\n",
       " 'flatten_1': <tensorflow.python.keras.layers.core.Flatten at 0xb3e298d68>,\n",
       " 'dense_layer': <tensorflow.python.keras.layers.core.Dense at 0xb3e298978>,\n",
       " 'norm_layer': <tensorflow.python.keras.layers.core.Lambda at 0xb3e2b2d68>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_model = create_model()\n",
    "face_model.load_weights('openface/model_weights.h5')\n",
    "\n",
    "# to help pick layers, since this model loads with different layer names each time due to how it's implemented\n",
    "layers_dict = {layer.name:layer for layer in face_model.layers}\n",
    "layers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [face_model.get_layer(name).output for name in layer_contributions.keys()]\n",
    "\n",
    "dreamer = tf.keras.Model(inputs=face_model.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [1,51,77,128] vs. shape[2] = [1,32,45,32] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-44c3b101c457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdreamer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mlayer_contributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_contributions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       output_path=output_path)\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects/tf2-deepdream/src/deepdream.py\u001b[0m in \u001b[0;36mdream\u001b[0;34m(image_path, model, layer_contributions, output_path, step, num_octave, octave_scale, iterations, max_loss, verbose)\u001b[0m\n\u001b[1;32m     56\u001b[0m                               \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                               \u001b[0mmax_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                               verbose=verbose)\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mupscaled_shrunk_original_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshrunk_original_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0msame_size_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tf2-deepdream/src/deepdream.py\u001b[0m in \u001b[0;36m_gradient_ascent\u001b[0;34m(x, model, layer_contributions, iterations, step, max_loss, verbose)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_contributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mgrad_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/tf2-deepdream/src/deepdream.py\u001b[0m in \u001b[0;36m_forward_loss\u001b[0;34m(x, model, layer_contributions)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_contributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mcoeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_contributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    659\u001b[0m               input_list, self._mixed_precision_policy.should_cast_variables):\n\u001b[0;32m--> 660\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    868\u001b[0m                                 ' implement a `call` method.')\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    659\u001b[0m               input_list, self._mixed_precision_policy.should_cast_variables):\n\u001b[0;32m--> 660\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36m_merge_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(tensors, axis)\u001b[0m\n\u001b[1;32m   2347\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2349\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1269\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1270\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1207\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [1,51,77,128] vs. shape[2] = [1,32,45,32] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "dreamed_image = dream(image_path, \n",
    "      model=dreamer, \n",
    "      layer_contributions=layer_contributions,\n",
    "      output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,13))\n",
    "plt.imshow(dreamed_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
